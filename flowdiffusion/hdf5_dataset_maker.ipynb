{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "def load_hdf5(dataset_dir, dataset_name):\n",
    "    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    with h5py.File(dataset_path, 'r') as root:\n",
    "        compressed = root.attrs.get('compress', False)\n",
    "        qpos = root['/observations/qpos'][()]\n",
    "        qvel = root['/observations/qvel'][()]\n",
    "        action = root['/action'][()]\n",
    "        image_dict = dict()\n",
    "        for cam_name in root[f'/observations/images/'].keys():\n",
    "            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n",
    "        if compressed:\n",
    "            compress_len = root['/compress_len'][()]\n",
    "\n",
    "    if compressed:\n",
    "        for cam_id, cam_name in enumerate(image_dict.keys()):\n",
    "            # un-pad and uncompress\n",
    "            padded_compressed_image_list = image_dict[cam_name]\n",
    "            image_list = []\n",
    "            for frame_id, padded_compressed_image in enumerate(padded_compressed_image_list): # [:1000] to save memory\n",
    "                compressed_image = padded_compressed_image\n",
    "                image = cv2.imdecode(compressed_image, 1)\n",
    "                image_list.append(image)\n",
    "            image_dict[cam_name] = image_list\n",
    "\n",
    "    return qpos, qvel, action, image_dict\n",
    "\n",
    "\n",
    "# dataset_dir = '/home/weixun/testing/avdc/datasets/hdf5_datasets/data'\n",
    "# dataset_name = 'episode_20'\n",
    "# qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "# print(qpos.shape)\n",
    "# print(qvel.shape)\n",
    "# print(action.shape)\n",
    "# print(image_dict.keys())\n",
    "# print(len(image_dict['cam_high']))\n",
    "# print(image_dict['cam_high'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_video_from_np_arrays(np_arrays, video_file, fps=50, target_size=(120, 160), square=False, skip_frames=3):\n",
    "    # Check if there are any arrays\n",
    "    if not np_arrays:\n",
    "        print(\"No numpy arrays provided\")\n",
    "        return\n",
    "\n",
    "    # Get size from the first array if not provided\n",
    "    # height, width, _ = np_arrays[0].shape\n",
    "    print(\"Shape Incoming: \", np_arrays[0].shape)\n",
    "    slicing_tuple = None\n",
    "\n",
    "    # if square, make the width and height the same by making the width shorter\n",
    "    if square:\n",
    "        img_sz = np_arrays[0].shape\n",
    "        # Get the larger dimension \n",
    "        dim_to_reduce = np.argmax(img_sz)\n",
    "        other = 1 if dim_to_reduce == 0 else 0\n",
    "\n",
    "        border = (img_sz[dim_to_reduce] - img_sz[other]) // 2\n",
    "        border_left = border\n",
    "        border_right = border + (img_sz[dim_to_reduce] - img_sz[other]) % 2\n",
    "        slice_range = slice(border_left, img_sz[dim_to_reduce] - border_right)\n",
    "        slicing_tuple = tuple(slice_range if i == dim_to_reduce else slice(None) for i in range(3))\n",
    "\n",
    "    new_lst = []\n",
    "    jump = skip_frames + 1\n",
    "    # Resize all arrays if needed\n",
    "    for i in range(len(np_arrays)):\n",
    "        if i % jump != 0:\n",
    "            continue\n",
    "        view_ = np_arrays[i][slicing_tuple] if slicing_tuple else np_arrays[i] \n",
    "        new_lst.append(cv2.resize(view_[:, :, ::-1], (target_size[1], target_size[0]))) # BGR to RGB and resize\n",
    "        # np_arrays[i] = cv2.resize(np_arrays[i], target_size)  # Resize array to match video size\n",
    "            \n",
    "        # print(\"New Shape: \", size)\n",
    "    print(\"Old Frame Count:\", len(np_arrays) , \" New Expected Frame Count, Actual: \", len(np_arrays)//jump, \" , \", len(new_lst))\n",
    "    print(\"New Shape: \", new_lst[0].shape)\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for .avi files or 'mp4v' for .mp4\n",
    "    video = cv2.VideoWriter(video_file, fourcc, fps, (target_size[1], target_size[0]))\n",
    "    \n",
    "    for array in new_lst:\n",
    "        video.write(array)\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  episode_14\n",
      "Loaded hdf5, took  3.2430408000946045\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_14  took  0.32219386100769043\n",
      "Processing  episode_25\n",
      "Loaded hdf5, took  3.2775440216064453\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_25  took  0.3152029514312744\n",
      "Processing  episode_18\n",
      "Loaded hdf5, took  3.2528488636016846\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_18  took  0.3671131134033203\n",
      "Processing  episode_13\n",
      "Loaded hdf5, took  3.7000105381011963\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_13  took  0.3766007423400879\n",
      "Processing  episode_5\n",
      "Loaded hdf5, took  3.669823408126831\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_5  took  0.3348088264465332\n",
      "Processing  episode_30\n",
      "Loaded hdf5, took  3.465956449508667\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_30  took  0.3819551467895508\n",
      "Processing  episode_8\n",
      "Loaded hdf5, took  3.7029595375061035\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_8  took  0.36994504928588867\n",
      "Processing  episode_48\n",
      "Loaded hdf5, took  3.650606393814087\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_48  took  0.33358097076416016\n",
      "Processing  episode_9\n",
      "Loaded hdf5, took  3.2664175033569336\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_9  took  0.34452319145202637\n",
      "Processing  episode_22\n",
      "Loaded hdf5, took  3.3526079654693604\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_22  took  0.3448617458343506\n",
      "Processing  episode_10\n",
      "Loaded hdf5, took  3.3658411502838135\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_10  took  0.34213829040527344\n",
      "Processing  episode_27\n",
      "Loaded hdf5, took  3.309220790863037\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_27  took  0.3382604122161865\n",
      "Processing  episode_20\n",
      "Loaded hdf5, took  3.320402145385742\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_20  took  0.3353159427642822\n",
      "Processing  episode_43\n",
      "Loaded hdf5, took  3.2798662185668945\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_43  took  0.34252381324768066\n",
      "Processing  episode_40\n",
      "Loaded hdf5, took  3.4765172004699707\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_40  took  0.37113022804260254\n",
      "Processing  episode_31\n",
      "Loaded hdf5, took  3.555272102355957\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_31  took  0.3553733825683594\n",
      "Processing  episode_44\n",
      "Loaded hdf5, took  3.3403446674346924\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_44  took  0.33369946479797363\n",
      "Processing  episode_11\n",
      "Loaded hdf5, took  3.2989273071289062\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_11  took  0.3319973945617676\n",
      "Processing  episode_23\n",
      "Loaded hdf5, took  3.2636873722076416\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_23  took  0.3385176658630371\n",
      "Processing  episode_16\n",
      "Loaded hdf5, took  3.2582149505615234\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_16  took  0.34388160705566406\n",
      "Processing  episode_42\n",
      "Loaded hdf5, took  3.2129650115966797\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_42  took  0.33666491508483887\n",
      "Processing  episode_0\n",
      "Loaded hdf5, took  3.1855039596557617\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_0  took  0.33403682708740234\n",
      "Processing  episode_29\n",
      "Loaded hdf5, took  3.167456865310669\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_29  took  0.3299582004547119\n",
      "Processing  episode_32\n",
      "Loaded hdf5, took  3.1564834117889404\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_32  took  0.33960986137390137\n",
      "Processing  episode_21\n",
      "Loaded hdf5, took  3.3373465538024902\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_21  took  0.3464500904083252\n",
      "Processing  episode_24\n",
      "Loaded hdf5, took  3.3193447589874268\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_24  took  0.34318065643310547\n",
      "Processing  episode_2\n",
      "Loaded hdf5, took  3.3391780853271484\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_2  took  0.3352370262145996\n",
      "Processing  episode_28\n",
      "Loaded hdf5, took  3.2081387042999268\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_28  took  0.3367621898651123\n",
      "Processing  episode_34\n",
      "Loaded hdf5, took  3.1640946865081787\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_34  took  0.3396129608154297\n",
      "Processing  episode_15\n",
      "Loaded hdf5, took  3.189619541168213\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_15  took  0.34003782272338867\n",
      "Processing  episode_37\n",
      "Loaded hdf5, took  3.1596312522888184\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_37  took  0.34104156494140625\n",
      "Processing  episode_46\n",
      "Loaded hdf5, took  3.181823253631592\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_46  took  0.3383166790008545\n",
      "Processing  episode_19\n",
      "Loaded hdf5, took  3.1670544147491455\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_19  took  0.3345222473144531\n",
      "Processing  episode_35\n",
      "Loaded hdf5, took  3.1722397804260254\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_35  took  0.3396615982055664\n",
      "Processing  episode_47\n",
      "Loaded hdf5, took  3.273102045059204\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_47  took  0.3361058235168457\n",
      "Processing  episode_49\n",
      "Loaded hdf5, took  3.212761640548706\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_49  took  0.34231090545654297\n",
      "Processing  episode_4\n",
      "Loaded hdf5, took  3.133410930633545\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_4  took  0.33179545402526855\n",
      "Processing  episode_12\n",
      "Loaded hdf5, took  3.2077348232269287\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_12  took  0.3335084915161133\n",
      "Processing  episode_36\n",
      "Loaded hdf5, took  3.5980827808380127\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_36  took  0.37602758407592773\n",
      "Processing  episode_41\n",
      "Loaded hdf5, took  3.560804605484009\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_41  took  0.3759274482727051\n",
      "Processing  episode_39\n",
      "Loaded hdf5, took  3.412383794784546\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_39  took  0.38066697120666504\n",
      "Processing  episode_7\n",
      "Loaded hdf5, took  3.636126756668091\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_7  took  0.38161325454711914\n",
      "Processing  episode_6\n",
      "Loaded hdf5, took  3.643617630004883\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_6  took  0.3370685577392578\n",
      "Processing  episode_26\n",
      "Loaded hdf5, took  3.5873045921325684\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_26  took  0.37658143043518066\n",
      "Processing  episode_45\n",
      "Loaded hdf5, took  3.6163668632507324\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_45  took  0.3933095932006836\n",
      "Processing  episode_1\n",
      "Loaded hdf5, took  3.668555498123169\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_1  took  0.3864777088165283\n",
      "Processing  episode_38\n",
      "Loaded hdf5, took  3.639636993408203\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_38  took  0.36869096755981445\n",
      "Processing  episode_17\n",
      "Loaded hdf5, took  3.5220699310302734\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_17  took  0.3554351329803467\n",
      "Processing  episode_33\n",
      "Loaded hdf5, took  3.303558826446533\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_33  took  0.34171485900878906\n",
      "Processing  episode_3\n",
      "Loaded hdf5, took  3.354243516921997\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (48, 64, 3)\n",
      "Processed Video episode_3  took  0.3415076732635498\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# dataset_dir = '/home/weixun/testing/avdc/datasets/hdf5_datasets/data'\n",
    "dataset_dir='/home/weixun/testing/avdc/datasets/hdf5_datasets/transfer_cube'\n",
    "dataset_name = 'episode_20'\n",
    "qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "cam = 'cam_low'\n",
    "\n",
    "for f in os.listdir(dataset_dir):\n",
    "    if not f.endswith('.hdf5'):\n",
    "        continue\n",
    "    dataset_name = f.split('.')[0]\n",
    "    print(\"Processing \", dataset_name)\n",
    "    start_time = time.time()\n",
    "    out_dir = os.path.join(dataset_dir, f'{dataset_name}_{cam}.mp4')\n",
    "    qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "    print(\"Loaded hdf5, took \", time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "    create_video_from_np_arrays(image_dict[cam], out_dir, fps=50, target_size=(120, 160))\n",
    "    print(\"Processed Video\", dataset_name, \" took \", time.time() - start_time)\n",
    "# dataset_name = \"episode_20\"\n",
    "# print(\"Processing \", dataset_name)\n",
    "# out_dir = os.path.join(dataset_dir, f'{dataset_name}_{cam}.mp4')\n",
    "# create_video_from_np_arrays(image_dict[cam], out_dir, fps=50, target_size=(128, 128), square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 3 parts:\n",
    "# - Pick up orange object with right arm | pick_up_orange_object_with_right_arm\n",
    "# - Hand over orange object to left arm | hand_over_orange_object_to_left_arm\n",
    "# - Place orange object in the blue square on the table | place_orange_object_in_blue_square_on_table_with_left_arm\n",
    "# Creating 3 directories with the respective videos\n",
    "parent_dir = os.path.join(dataset_dir, 'vidgen_datasets')\n",
    "rhp_dir = os.path.join(parent_dir, 'right_hand_pick')\n",
    "hol_dir = os.path.join(parent_dir, 'hand_over_left')\n",
    "pob_dir = os.path.join(parent_dir, 'place_on_blue')\n",
    "\n",
    "for d in [parent_dir, rhp_dir, hol_dir, pob_dir]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  episode_38_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_0_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_25_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_9_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_31_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_47_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_26_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_34_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_32_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_21_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_14_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_2_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_39_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_1_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_37_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_19_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_12_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_17_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_7_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_46_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_11_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_30_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_13_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_22_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_40_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_49_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_33_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_35_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_10_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_24_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_18_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_5_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_8_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_23_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_27_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_45_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_48_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_43_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_42_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_44_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_20_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_4_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_29_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_15_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_6_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_16_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_28_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_36_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_41_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_3_cam_low.mp4\n",
      "Total Frames:  400\n"
     ]
    }
   ],
   "source": [
    "# Spliting the videos into 3 smaller videos, split them equally.\n",
    "# First 1/3 of the video is for right hand pick, next 1/3 is for hand over left, last 1/3 is for place on blue\n",
    "# Process each video file\n",
    "for f in os.listdir(dataset_dir):\n",
    "    if not f.endswith('.mp4'):\n",
    "        continue\n",
    "    \n",
    "    print(\"Processing \", f)\n",
    "    cap = cv2.VideoCapture(os.path.join(dataset_dir, f))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(\"Total Frames: \", total_frames)\n",
    "    \n",
    "    # Define VideoWriters for the three output videos\n",
    "    rhp_writer = cv2.VideoWriter(os.path.join(rhp_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    hol_writer = cv2.VideoWriter(os.path.join(hol_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    pob_writer = cv2.VideoWriter(os.path.join(pob_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count < total_frames // 3:\n",
    "            rhp_writer.write(frame)\n",
    "        elif frame_count < 9 * total_frames // 12: # Adjusted ratio to allow for more frames in hand over left\n",
    "            hol_writer.write(frame)\n",
    "        else:\n",
    "            pob_writer.write(frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    rhp_writer.release()\n",
    "    hol_writer.release()\n",
    "    pob_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for vidgen, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path '/home/weixun/testing/avdc' has been added to the Python path.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def add_to_python_path(path):\n",
    "    # Get the absolute path to ensure we are checking the correct path\n",
    "    absolute_path = os.path.abspath(path)\n",
    "    \n",
    "    # Check if the path is already in sys.path\n",
    "    if absolute_path in sys.path:\n",
    "        print(f\"The path '{absolute_path}' is already in the Python path.\")\n",
    "    else:\n",
    "        # If not, add it to sys.path\n",
    "        sys.path.append(absolute_path)\n",
    "        print(f\"The path '{absolute_path}' has been added to the Python path.\")\n",
    "add_to_python_path(\"/home/weixun/testing/avdc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import flowdiffusion.datasets\n",
    "importlib.reload(flowdiffusion.datasets)\n",
    "del SequentialDatasetNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "SEQLEN:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/bridge/numpy/bridge_data_v1/berkeley/toykitchen4/put_banana_in_pot_or_pan/val\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SequentialDatasetNp(file_path)\n\u001b[0;32m----> 8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of dataloader: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataloader))\n",
      "File \u001b[0;32m~/anaconda3/envs/avdc/lib/python3.9/site-packages/torch/utils/data/dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/avdc/lib/python3.9/site-packages/torch/utils/data/sampler.py:144\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Import the module and reload it to ensure changes are applied\n",
    "from flowdiffusion.datasets import SequentialDatasetNp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "file_path = './datasets/bridge/numpy/bridge_data_v1/berkeley/toykitchen4/put_banana_in_pot_or_pan/val'\n",
    "dataset = SequentialDatasetNp(file_path)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "print(\"Length of dataloader: \", len(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_hdf5(dataset_dir, skip_mirrored_data):\n",
    "    hdf5_files = []\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for filename in fnmatch.filter(files, '*.hdf5'):\n",
    "            if 'features' in filename: continue\n",
    "            if skip_mirrored_data and 'mirror' in filename:\n",
    "                continue\n",
    "            hdf5_files.append(os.path.join(root, filename))\n",
    "    print(f'Found {len(hdf5_files)} hdf5 files')\n",
    "    return hdf5_files\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def load_data(dataset_dir_l, name_filter, camera_names, batch_size_train, batch_size_val, chunk_size, skip_mirrored_data=False, policy_class=None, stats_dir_l=None, sample_weights=None, train_ratio=0.99):\n",
    "    if type(dataset_dir_l) == str:\n",
    "        dataset_dir_l = [dataset_dir_l]\n",
    "    dataset_path_list_list = [find_all_hdf5(dataset_dir, skip_mirrored_data) for dataset_dir in dataset_dir_l]\n",
    "    num_episodes_0 = len(dataset_path_list_list[0])\n",
    "    dataset_path_list = flatten_list(dataset_path_list_list)\n",
    "    dataset_path_list = [n for n in dataset_path_list if name_filter(n)]\n",
    "    num_episodes_l = [len(dataset_path_list) for dataset_path_list in dataset_path_list_list]\n",
    "    num_episodes_cumsum = np.cumsum(num_episodes_l)\n",
    "\n",
    "    # obtain train test split on dataset_dir_l[0]\n",
    "    shuffled_episode_ids_0 = np.random.permutation(num_episodes_0)\n",
    "    train_episode_ids_0 = shuffled_episode_ids_0[:int(train_ratio * num_episodes_0)]\n",
    "    val_episode_ids_0 = shuffled_episode_ids_0[int(train_ratio * num_episodes_0):]\n",
    "    train_episode_ids_l = [train_episode_ids_0] + [np.arange(num_episodes) + num_episodes_cumsum[idx] for idx, num_episodes in enumerate(num_episodes_l[1:])]\n",
    "    val_episode_ids_l = [val_episode_ids_0]\n",
    "    train_episode_ids = np.concatenate(train_episode_ids_l)\n",
    "    val_episode_ids = np.concatenate(val_episode_ids_l)\n",
    "    print(f'\\n\\nData from: {dataset_dir_l}\\n- Train on {[len(x) for x in train_episode_ids_l]} episodes\\n- Test on {[len(x) for x in val_episode_ids_l]} episodes\\n\\n')\n",
    "    _, all_episode_len = get_norm_stats(dataset_path_list)\n",
    "    train_episode_len_l = [[all_episode_len[i] for i in train_episode_ids] for train_episode_ids in train_episode_ids_l]\n",
    "    val_episode_len_l = [[all_episode_len[i] for i in val_episode_ids] for val_episode_ids in val_episode_ids_l]\n",
    "    train_episode_len = flatten_list(train_episode_len_l)\n",
    "    val_episode_len = flatten_list(val_episode_len_l)\n",
    "    if stats_dir_l is None:\n",
    "        stats_dir_l = dataset_dir_l\n",
    "    elif type(stats_dir_l) == str:\n",
    "        stats_dir_l = [stats_dir_l]\n",
    "    norm_stats, _ = get_norm_stats(flatten_list([find_all_hdf5(stats_dir, skip_mirrored_data) for stats_dir in stats_dir_l]))\n",
    "    print(f'Norm stats from: {stats_dir_l}')\n",
    "\n",
    "    batch_sampler_train = BatchSampler(batch_size_train, train_episode_len_l, sample_weights)\n",
    "    batch_sampler_val = BatchSampler(batch_size_val, val_episode_len_l, None)\n",
    "\n",
    "    # construct dataset and dataloader\n",
    "    train_dataset = EpisodicDataset(dataset_path_list, camera_names, norm_stats, train_episode_ids, train_episode_len, chunk_size, policy_class)\n",
    "    val_dataset = EpisodicDataset(dataset_path_list, camera_names, norm_stats, val_episode_ids, val_episode_len, chunk_size, policy_class)\n",
    "    train_num_workers = 6 if train_dataset.augment_images else 2\n",
    "    val_num_workers = 6 if train_dataset.augment_images else 2\n",
    "    print(f'Augment images: {train_dataset.augment_images}, train_num_workers: {train_num_workers}, val_num_workers: {val_num_workers}')\n",
    "    train_dataloader = DataLoader(train_dataset, batch_sampler=batch_sampler_train, pin_memory=True, num_workers=train_num_workers, prefetch_factor=2)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_sampler=batch_sampler_val, pin_memory=True, num_workers=val_num_workers, prefetch_factor=2)\n",
    "\n",
    "    return train_dataloader, val_dataloader, norm_stats, train_dataset.is_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
