{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "def load_hdf5(dataset_dir, dataset_name):\n",
    "    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    with h5py.File(dataset_path, 'r') as root:\n",
    "        compressed = root.attrs.get('compress', False)\n",
    "        qpos = root['/observations/qpos'][()]\n",
    "        qvel = root['/observations/qvel'][()]\n",
    "        action = root['/action'][()]\n",
    "        image_dict = dict()\n",
    "        for cam_name in root[f'/observations/images/'].keys():\n",
    "            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n",
    "        if compressed:\n",
    "            compress_len = root['/compress_len'][()]\n",
    "\n",
    "    if compressed:\n",
    "        for cam_id, cam_name in enumerate(image_dict.keys()):\n",
    "            # un-pad and uncompress\n",
    "            padded_compressed_image_list = image_dict[cam_name]\n",
    "            image_list = []\n",
    "            for frame_id, padded_compressed_image in enumerate(padded_compressed_image_list): # [:1000] to save memory\n",
    "                compressed_image = padded_compressed_image\n",
    "                image = cv2.imdecode(compressed_image, 1)\n",
    "                image_list.append(image)\n",
    "            image_dict[cam_name] = image_list\n",
    "\n",
    "    return qpos, qvel, action, image_dict\n",
    "\n",
    "\n",
    "# dataset_dir = '/home/weixun/testing/avdc/datasets/hdf5_datasets/data'\n",
    "# dataset_name = 'episode_20'\n",
    "# qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "# print(qpos.shape)\n",
    "# print(qvel.shape)\n",
    "# print(action.shape)\n",
    "# print(image_dict.keys())\n",
    "# print(len(image_dict['cam_high']))\n",
    "# print(image_dict['cam_high'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_video_from_np_arrays(np_arrays, video_file, target_size=None, fps=50, square=False, skip_frames=3):\n",
    "    # Check if there are any arrays\n",
    "    if not np_arrays:\n",
    "        print(\"No numpy arrays provided\")\n",
    "        return\n",
    "    if target_size is None:\n",
    "        target_size = np_arrays[0].shape[:2]\n",
    "\n",
    "    # Get size from the first array if not provided\n",
    "    # height, width, _ = np_arrays[0].shape\n",
    "    print(\"Shape Incoming: \", np_arrays[0].shape)\n",
    "    slicing_tuple = None\n",
    "\n",
    "    # if square, make the width and height the same by making the width shorter\n",
    "    if square:\n",
    "        img_sz = np_arrays[0].shape\n",
    "        # Get the larger dimension \n",
    "        dim_to_reduce = np.argmax(img_sz)\n",
    "        other = 1 if dim_to_reduce == 0 else 0\n",
    "\n",
    "        border = (img_sz[dim_to_reduce] - img_sz[other]) // 2\n",
    "        border_left = border\n",
    "        border_right = border + (img_sz[dim_to_reduce] - img_sz[other]) % 2\n",
    "        slice_range = slice(border_left, img_sz[dim_to_reduce] - border_right)\n",
    "        slicing_tuple = tuple(slice_range if i == dim_to_reduce else slice(None) for i in range(3))\n",
    "\n",
    "    new_lst = []\n",
    "    jump = skip_frames + 1\n",
    "    # Resize all arrays if needed\n",
    "    for i in range(len(np_arrays)):\n",
    "        if i % jump != 0:\n",
    "            continue\n",
    "        view_ = np_arrays[i][slicing_tuple] if slicing_tuple else np_arrays[i] \n",
    "        new_lst.append(cv2.resize(view_[:, :, ::-1], (target_size[1], target_size[0]))) # BGR to RGB and resize\n",
    "        # np_arrays[i] = cv2.resize(np_arrays[i], target_size)  # Resize array to match video size\n",
    "            \n",
    "        # print(\"New Shape: \", size)\n",
    "    print(\"Old Frame Count:\", len(np_arrays) , \" New Expected Frame Count, Actual: \", len(np_arrays)//jump, \" , \", len(new_lst))\n",
    "    print(\"New Shape: \", new_lst[0].shape)\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for .avi files or 'mp4v' for .mp4\n",
    "    video = cv2.VideoWriter(video_file, fourcc, fps, (target_size[1], target_size[0]))\n",
    "    \n",
    "    for array in new_lst:\n",
    "        video.write(array)\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  episode_14\n",
      "Loaded hdf5, took  4.4258034229278564\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_14  took  0.85148024559021\n",
      "Processing  episode_25\n",
      "Loaded hdf5, took  3.3004820346832275\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_25  took  0.7931482791900635\n",
      "Processing  episode_18\n",
      "Loaded hdf5, took  3.7412238121032715\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_18  took  0.8531761169433594\n",
      "Processing  episode_13\n",
      "Loaded hdf5, took  3.193129539489746\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_13  took  0.7722103595733643\n",
      "Processing  episode_5\n",
      "Loaded hdf5, took  3.200157642364502\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_5  took  0.8776309490203857\n",
      "Processing  episode_30\n",
      "Loaded hdf5, took  3.2056736946105957\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_30  took  0.7642898559570312\n",
      "Processing  episode_8\n",
      "Loaded hdf5, took  3.2017245292663574\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_8  took  0.774730920791626\n",
      "Processing  episode_48\n",
      "Loaded hdf5, took  3.2240004539489746\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_48  took  0.778130292892456\n",
      "Processing  episode_9\n",
      "Loaded hdf5, took  3.230548620223999\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_9  took  0.8036031723022461\n",
      "Processing  episode_22\n",
      "Loaded hdf5, took  3.2461371421813965\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_22  took  0.79471755027771\n",
      "Processing  episode_10\n",
      "Loaded hdf5, took  3.238337755203247\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_10  took  0.8137223720550537\n",
      "Processing  episode_27\n",
      "Loaded hdf5, took  3.2460803985595703\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_27  took  0.7749178409576416\n",
      "Processing  episode_20\n",
      "Loaded hdf5, took  3.2386627197265625\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_20  took  0.7911646366119385\n",
      "Processing  episode_43\n",
      "Loaded hdf5, took  3.3107235431671143\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_43  took  0.7917325496673584\n",
      "Processing  episode_40\n",
      "Loaded hdf5, took  3.2126452922821045\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_40  took  0.788541316986084\n",
      "Processing  episode_31\n",
      "Loaded hdf5, took  3.2493252754211426\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_31  took  0.7741730213165283\n",
      "Processing  episode_44\n",
      "Loaded hdf5, took  3.272115468978882\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_44  took  0.7993872165679932\n",
      "Processing  episode_11\n",
      "Loaded hdf5, took  3.22212553024292\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_11  took  0.8061351776123047\n",
      "Processing  episode_23\n",
      "Loaded hdf5, took  3.222414493560791\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_23  took  0.7862770557403564\n",
      "Processing  episode_16\n",
      "Loaded hdf5, took  3.2847354412078857\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_16  took  0.8501708507537842\n",
      "Processing  episode_42\n",
      "Loaded hdf5, took  3.206984281539917\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_42  took  0.7737395763397217\n",
      "Processing  episode_0\n",
      "Loaded hdf5, took  3.273928642272949\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_0  took  0.7825353145599365\n",
      "Processing  episode_29\n",
      "Loaded hdf5, took  3.229685068130493\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_29  took  0.8012206554412842\n",
      "Processing  episode_32\n",
      "Loaded hdf5, took  3.252060651779175\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_32  took  0.7945551872253418\n",
      "Processing  episode_21\n",
      "Loaded hdf5, took  3.306337594985962\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_21  took  0.8079876899719238\n",
      "Processing  episode_24\n",
      "Loaded hdf5, took  3.326000928878784\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_24  took  0.8472003936767578\n",
      "Processing  episode_2\n",
      "Loaded hdf5, took  3.308149814605713\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_2  took  0.805924654006958\n",
      "Processing  episode_28\n",
      "Loaded hdf5, took  3.3591129779815674\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_28  took  0.8220300674438477\n",
      "Processing  episode_34\n",
      "Loaded hdf5, took  3.358220338821411\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_34  took  0.8126571178436279\n",
      "Processing  episode_15\n",
      "Loaded hdf5, took  3.289957284927368\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_15  took  0.8095180988311768\n",
      "Processing  episode_37\n",
      "Loaded hdf5, took  3.266688823699951\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_37  took  0.804826021194458\n",
      "Processing  episode_46\n",
      "Loaded hdf5, took  3.289485454559326\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_46  took  0.8030669689178467\n",
      "Processing  episode_19\n",
      "Loaded hdf5, took  3.261159896850586\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_19  took  0.8061132431030273\n",
      "Processing  episode_35\n",
      "Loaded hdf5, took  3.233273506164551\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_35  took  0.7759754657745361\n",
      "Processing  episode_47\n",
      "Loaded hdf5, took  3.196552276611328\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_47  took  0.781562089920044\n",
      "Processing  episode_49\n",
      "Loaded hdf5, took  3.20904803276062\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_49  took  0.7853941917419434\n",
      "Processing  episode_4\n",
      "Loaded hdf5, took  3.1920506954193115\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_4  took  0.8020479679107666\n",
      "Processing  episode_12\n",
      "Loaded hdf5, took  3.1983275413513184\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_12  took  0.7821269035339355\n",
      "Processing  episode_36\n",
      "Loaded hdf5, took  3.1311511993408203\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_36  took  0.8380663394927979\n",
      "Processing  episode_41\n",
      "Loaded hdf5, took  3.19376277923584\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_41  took  0.8268985748291016\n",
      "Processing  episode_39\n",
      "Loaded hdf5, took  3.2641053199768066\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_39  took  0.7876405715942383\n",
      "Processing  episode_7\n",
      "Loaded hdf5, took  3.2236599922180176\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_7  took  0.7982423305511475\n",
      "Processing  episode_6\n",
      "Loaded hdf5, took  3.2260074615478516\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_6  took  0.7972233295440674\n",
      "Processing  episode_26\n",
      "Loaded hdf5, took  3.2262954711914062\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_26  took  0.7925577163696289\n",
      "Processing  episode_45\n",
      "Loaded hdf5, took  3.3774147033691406\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_45  took  0.9142823219299316\n",
      "Processing  episode_1\n",
      "Loaded hdf5, took  3.370314836502075\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_1  took  0.8370623588562012\n",
      "Processing  episode_38\n",
      "Loaded hdf5, took  3.3769946098327637\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_38  took  0.7941393852233887\n",
      "Processing  episode_17\n",
      "Loaded hdf5, took  3.3156278133392334\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_17  took  0.8037455081939697\n",
      "Processing  episode_33\n",
      "Loaded hdf5, took  3.1730072498321533\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_33  took  0.8390569686889648\n",
      "Processing  episode_3\n",
      "Loaded hdf5, took  3.4136605262756348\n",
      "Shape Incoming:  (480, 640, 3)\n",
      "Old Frame Count: 1600  New Expected Frame Count, Actual:  400  ,  400\n",
      "New Shape:  (480, 640, 3)\n",
      "Processed Video episode_3  took  0.8168606758117676\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# dataset_dir = '/home/weixun/testing/avdc/datasets/hdf5_datasets/data'\n",
    "dataset_dir='/home/weixun/testing/avdc/datasets/hdf5_datasets/transfer_cube'\n",
    "dataset_name = 'episode_20'\n",
    "qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "cam = 'cam_low'\n",
    "\n",
    "for f in os.listdir(dataset_dir):\n",
    "    if not f.endswith('.hdf5'):\n",
    "        continue\n",
    "    dataset_name = f.split('.')[0]\n",
    "    print(\"Processing \", dataset_name)\n",
    "    start_time = time.time()\n",
    "    out_dir = os.path.join(dataset_dir, f'{dataset_name}_{cam}.mp4')\n",
    "    qpos, qvel, action, image_dict = load_hdf5(dataset_dir, dataset_name)\n",
    "    print(\"Loaded hdf5, took \", time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "    create_video_from_np_arrays(image_dict[cam], out_dir, fps=50)\n",
    "    print(\"Processed Video\", dataset_name, \" took \", time.time() - start_time)\n",
    "# dataset_name = \"episode_20\"\n",
    "# print(\"Processing \", dataset_name)\n",
    "# out_dir = os.path.join(dataset_dir, f'{dataset_name}_{cam}.mp4')\n",
    "# create_video_from_np_arrays(image_dict[cam], out_dir, fps=50, target_size=(128, 128), square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 3 parts:\n",
    "# - Pick up orange object with right arm | pick_up_orange_object_with_right_arm\n",
    "# - Hand over orange object to left arm | hand_over_orange_object_to_left_arm\n",
    "# - Place orange object in the blue square on the table | place_orange_object_in_blue_square_on_table_with_left_arm\n",
    "# Creating 3 directories with the respective videos\n",
    "parent_dir = os.path.join(dataset_dir, 'vidgen_datasets')\n",
    "rhp_dir = os.path.join(parent_dir, 'right_hand_pick')\n",
    "hol_dir = os.path.join(parent_dir, 'hand_over_left')\n",
    "pob_dir = os.path.join(parent_dir, 'place_on_blue')\n",
    "\n",
    "for d in [parent_dir, rhp_dir, hol_dir, pob_dir]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  episode_38_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_0_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_25_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_9_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_31_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_47_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_26_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_34_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_32_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_21_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_14_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_2_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_39_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_1_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_37_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_19_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_12_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_17_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_7_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_46_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_11_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_30_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_13_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_22_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_40_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_49_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_33_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_35_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_10_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_24_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_18_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_5_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_8_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_23_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_27_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_45_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_48_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_43_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_42_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_44_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_20_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_4_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_29_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_15_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_6_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_16_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_28_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_36_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_41_cam_low.mp4\n",
      "Total Frames:  400\n",
      "Processing  episode_3_cam_low.mp4\n",
      "Total Frames:  400\n"
     ]
    }
   ],
   "source": [
    "# Spliting the videos into 3 smaller videos, split them equally.\n",
    "# First 1/3 of the video is for right hand pick, next 1/3 is for hand over left, last 1/3 is for place on blue\n",
    "# Process each video file\n",
    "for f in os.listdir(dataset_dir):\n",
    "    if not f.endswith('.mp4'):\n",
    "        continue\n",
    "    \n",
    "    print(\"Processing \", f)\n",
    "    cap = cv2.VideoCapture(os.path.join(dataset_dir, f))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(\"Total Frames: \", total_frames)\n",
    "    \n",
    "    # Define VideoWriters for the three output videos\n",
    "    rhp_writer = cv2.VideoWriter(os.path.join(rhp_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    hol_writer = cv2.VideoWriter(os.path.join(hol_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    pob_writer = cv2.VideoWriter(os.path.join(pob_dir, f), cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count < total_frames // 3:\n",
    "            rhp_writer.write(frame)\n",
    "        elif frame_count < 9 * total_frames // 12: # Adjusted ratio to allow for more frames in hand over left\n",
    "            hol_writer.write(frame)\n",
    "        else:\n",
    "            pob_writer.write(frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    rhp_writer.release()\n",
    "    hol_writer.release()\n",
    "    pob_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for vidgen, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path '/home/weixun/testing/avdc' has been added to the Python path.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def add_to_python_path(path):\n",
    "    # Get the absolute path to ensure we are checking the correct path\n",
    "    absolute_path = os.path.abspath(path)\n",
    "    \n",
    "    # Check if the path is already in sys.path\n",
    "    if absolute_path in sys.path:\n",
    "        print(f\"The path '{absolute_path}' is already in the Python path.\")\n",
    "    else:\n",
    "        # If not, add it to sys.path\n",
    "        sys.path.append(absolute_path)\n",
    "        print(f\"The path '{absolute_path}' has been added to the Python path.\")\n",
    "add_to_python_path(\"/home/weixun/testing/avdc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import flowdiffusion.datasets\n",
    "importlib.reload(flowdiffusion.datasets)\n",
    "del SequentialDatasetNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "SEQLEN:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/bridge/numpy/bridge_data_v1/berkeley/toykitchen4/put_banana_in_pot_or_pan/val\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SequentialDatasetNp(file_path)\n\u001b[0;32m----> 8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of dataloader: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataloader))\n",
      "File \u001b[0;32m~/anaconda3/envs/avdc/lib/python3.9/site-packages/torch/utils/data/dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/avdc/lib/python3.9/site-packages/torch/utils/data/sampler.py:144\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Import the module and reload it to ensure changes are applied\n",
    "from flowdiffusion.datasets import SequentialDatasetNp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "file_path = './datasets/bridge/numpy/bridge_data_v1/berkeley/toykitchen4/put_banana_in_pot_or_pan/val'\n",
    "dataset = SequentialDatasetNp(file_path)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "print(\"Length of dataloader: \", len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitting Task Video Separation\n",
    "**Doing 6 separations:**\n",
    "1. Start to Right hand first grab + dt frames (First Sharp Increase)\n",
    "2. Up until Right hand first release + dt frames\n",
    "3. Up until Left hand first grab + dt frames\n",
    "4. Up until Left hand first release + dt frames\n",
    "5. Up until Right hand last grab + dt frames\n",
    "6. Last grab to end of video last release + dt frames to end of vid (If the last grab is before the last release, take the 2nd last grab)\n",
    "    - Last grab and release threshold 0.02\n",
    "\n",
    "~ Kinda like Regex\n",
    "\n",
    "#### Small Notes:\n",
    "1. Should also try to make IK model predict whether or not gripper is open or closed even if it can't infer information from image? \n",
    "    - Try making it learn and one not making it learn.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "def load_hdf5(dataset_dir, dataset_name):\n",
    "    dataset_path = os.path.join(dataset_dir, dataset_name)\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    with h5py.File(dataset_path, 'r') as root:\n",
    "        compressed = root.attrs.get('compress', False)\n",
    "        qpos = root['/observations/qpos'][()]\n",
    "        qvel = root['/observations/qvel'][()]\n",
    "        action = root['/action'][()]\n",
    "        image_dict = dict()\n",
    "        for cam_name in root[f'/observations/images/'].keys():\n",
    "            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n",
    "        if compressed:\n",
    "            compress_len = root['/compress_len'][()]\n",
    "\n",
    "    if compressed:\n",
    "        for cam_id, cam_name in enumerate(image_dict.keys()):\n",
    "            # un-pad and uncompress\n",
    "            padded_compressed_image_list = image_dict[cam_name]\n",
    "            image_list = []\n",
    "            for frame_id, padded_compressed_image in enumerate(padded_compressed_image_list): # [:1000] to save memory\n",
    "                compressed_image = padded_compressed_image\n",
    "                image = cv2.imdecode(compressed_image, 1)\n",
    "                image_list.append(image)\n",
    "            image_dict[cam_name] = image_list\n",
    "\n",
    "    return qpos, qvel, action, image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing + sharp Drop in Gripper State.\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
